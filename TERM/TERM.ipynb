{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUAfe7yCRvun",
        "outputId": "5d97424d-b2b6-4d4f-b8a9-b20a9502547c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TERM'...\n",
            "remote: Enumerating objects: 258, done.\u001b[K\n",
            "remote: Counting objects: 100% (258/258), done.\u001b[K\n",
            "remote: Compressing objects: 100% (192/192), done.\u001b[K\n",
            "remote: Total 258 (delta 80), reused 219 (delta 55), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (258/258), 5.78 MiB | 11.09 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/litian96/TERM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define data transformations\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "id": "CGsHIB37SNFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4b6a2d-1b13-4b2a-8b8b-2cd0de960766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:08<00:00, 20348096.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def corrupt_label(training_labels):\n",
        "    \"\"\"\n",
        "    training_labels: clean training labels\n",
        "    return: corrupted labels\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(1)\n",
        "    num_annotator = 5\n",
        "    label_ = int(len(training_labels)/num_annotator)\n",
        "    noise_ratio = [0, 0.2, 0.4, 1, -1]  # -1 means total adversarial\n",
        "    noisy = np.array(noise_ratio) * label_\n",
        "\n",
        "    normal_ind = []\n",
        "    normal_ind.extend(range(label_))\n",
        "\n",
        "    for i in range(num_annotator):\n",
        "        if noise_ratio[i] > 0:\n",
        "            training_labels[i * label_ : i * label_ + int(noisy[i])] = np.random.choice(10, int(noisy[i]))\n",
        "            training_labels[i * label_ : (i+1) * label_] = [l + i * 100 for l in training_labels[i * label_ : (i+1) * label_]]\n",
        "            normal_ind.extend(range(i * label_ + int(noisy[i]), (i+1)*label_))\n",
        "        elif noise_ratio[i] == -1:\n",
        "            # adversarial\n",
        "            training_labels[i * label_: (i + 1) * label_] = [(l+1) % 10 + i * 100 for l in\n",
        "                                                             training_labels[i * label_: (i + 1) * label_]]\n",
        "\n",
        "    return training_labels, np.array(normal_ind).flatten()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T4VnPSI3R5q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Properly implemented ResNet-s for CIFAR10 as described in paper [1].\n",
        "\n",
        "The implementation and structure of this file is hugely influenced by [2]\n",
        "which is implemented for ImageNet and doesn't have option A for identity.\n",
        "Moreover, most of the implementations on the web is copy-paste from\n",
        "torchvision's resnet and has wrong number of params.\n",
        "\n",
        "Proper ResNet-s for CIFAR10 (for fair comparision and etc.) has following\n",
        "number of layers and parameters:\n",
        "\n",
        "name      | layers | params\n",
        "ResNet20  |    20  | 0.27M\n",
        "ResNet32  |    32  | 0.46M\n",
        "ResNet44  |    44  | 0.66M\n",
        "ResNet56  |    56  | 0.85M\n",
        "ResNet110 |   110  |  1.7M\n",
        "ResNet1202|  1202  | 19.4m\n",
        "\n",
        "which this implementation indeed has.\n",
        "\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "[2] https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
        "\n",
        "If you use this implementation in you work, please don't forget to mention the\n",
        "author, Yerlan Idelbayev.\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
        "\n",
        "def _weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    #print(classname)\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight)\n",
        "\n",
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            if option == 'A':\n",
        "                \"\"\"\n",
        "                For CIFAR10 ResNet paper uses option A.\n",
        "                \"\"\"\n",
        "                self.shortcut = LambdaLayer(lambda x:\n",
        "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
        "            elif option == 'B':\n",
        "                self.shortcut = nn.Sequential(\n",
        "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                     nn.BatchNorm2d(self.expansion * planes)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "        self.apply(_weights_init)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def resnet20():\n",
        "    return ResNet(BasicBlock, [3, 3, 3])\n",
        "\n",
        "\n",
        "def resnet32():\n",
        "    return ResNet(BasicBlock, [5, 5, 5])\n",
        "\n",
        "\n",
        "def resnet44():\n",
        "    return ResNet(BasicBlock, [7, 7, 7])\n",
        "\n",
        "\n",
        "def resnet56():\n",
        "    return ResNet(BasicBlock, [9, 9, 9])\n",
        "\n",
        "\n",
        "def resnet110():\n",
        "    return ResNet(BasicBlock, [18, 18, 18])\n",
        "\n",
        "\n",
        "def resnet1202():\n",
        "    return ResNet(BasicBlock, [200, 200, 200])\n",
        "\n",
        "\n",
        "def test(net):\n",
        "    import numpy as np\n",
        "    total_params = 0\n",
        "\n",
        "    for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
        "        total_params += np.prod(x.data.numpy().shape)\n",
        "    print(\"Total number of params\", total_params)\n",
        "    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for net_name in __all__:\n",
        "        if net_name.startswith('resnet'):\n",
        "            print(net_name)\n",
        "            test(globals()[net_name]())\n",
        "            print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKoN9cWASAbH",
        "outputId": "c8092bbd-d092-4ef2-c99c-393bea672ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet20\n",
            "Total number of params 269722\n",
            "Total layers 20\n",
            "\n",
            "resnet32\n",
            "Total number of params 464154\n",
            "Total layers 32\n",
            "\n",
            "resnet44\n",
            "Total number of params 658586\n",
            "Total layers 44\n",
            "\n",
            "resnet56\n",
            "Total number of params 853018\n",
            "Total layers 56\n",
            "\n",
            "resnet110\n",
            "Total number of params 1727962\n",
            "Total layers 110\n",
            "\n",
            "resnet1202\n",
            "Total number of params 19421274\n",
            "Total layers 1202\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install resnet\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5N-8LxmSp6b",
        "outputId": "f646a445-1db9-4b1f-90ce-2564380a5ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting resnet\n",
            "  Downloading resnet-0.1.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: keras>=2.0 in /usr/local/lib/python3.10/dist-packages (from resnet) (2.14.0)\n",
            "Building wheels for collected packages: resnet\n",
            "  Building wheel for resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for resnet: filename=resnet-0.1-py3-none-any.whl size=10026 sha256=e9b498d340d7ca1141de6ea4d5653ae043a79d0b77c193f2a1b20749264fedd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/62/ef/ac6244da70f4650a13902e0294d88e71cf950b4fb8dbeccb98\n",
            "Successfully built resnet\n",
            "Installing collected packages: resnet\n",
            "Successfully installed resnet-0.1\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import resnet\n",
        "\n",
        "from cifar10 import corrupt_label\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "model_names = sorted(name for name in resnet.__dict__\n",
        "                     if name.islower() and not name.startswith(\"__\")\n",
        "                     and name.startswith(\"resnet\")\n",
        "                     and callable(resnet.__dict__[name]))\n",
        "\n",
        "print(model_names)\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Propert ResNets for CIFAR10 in pytorch')\n",
        "parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet20',\n",
        "                    choices=model_names,\n",
        "                    help='model architecture: ' + ' | '.join(model_names) +\n",
        "                         ' (default: resnet20)')\n",
        "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
        "                    help='number of data loading workers (default: 4)')\n",
        "parser.add_argument('--epochs', default=100, type=int, metavar='N',\n",
        "                    help='number of total epochs to run')\n",
        "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
        "                    help='manual epoch number (useful on restarts)')\n",
        "parser.add_argument('--batch_size', default=100, type=int,\n",
        "                    metavar='N', help='mini-batch size (default: 100)')\n",
        "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
        "                    metavar='LR', help='initial learning rate')\n",
        "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
        "                    help='momentum')\n",
        "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
        "                    metavar='W', help='weight decay (default: 1e-4)')\n",
        "parser.add_argument('--print-freq', '-p', default=50, type=int,\n",
        "                    metavar='N', help='print frequency (default: 50)')\n",
        "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
        "                    help='path to latest checkpoint (default: none)')\n",
        "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
        "                    help='evaluate model on validation set')\n",
        "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
        "                    help='use pre-trained model')\n",
        "parser.add_argument('--half', dest='half', action='store_true',\n",
        "                    help='use half-precision(16-bit) ')\n",
        "parser.add_argument('--save-dir', dest='save_dir',\n",
        "                    help='The directory used to save the trained models',\n",
        "                    default='save_temp', type=str)\n",
        "parser.add_argument('--save-every', dest='save_every',\n",
        "                    help='Saves checkpoints at every specified number of epochs',\n",
        "                    type=int, default=10)\n",
        "parser.add_argument('--genie', dest='genie', action='store_true',\n",
        "                    help='whether to use genie erm')\n",
        "\n",
        "\n",
        "best_prec1 = 0\n",
        "\n",
        "\n",
        "def main():\n",
        "    global args, best_prec1\n",
        "    parser = argparse.ArgumentParser(description='Propert ResNets for CIFAR10 in pytorch')\n",
        "\n",
        "    parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet20',\n",
        "                        choices=['resnet110', 'resnet1202', 'resnet20', 'resnet32', 'resnet44', 'resnet56'],\n",
        "                        help='model architecture: ' + ' | '.join(['resnet110', 'resnet1202', 'resnet20', 'resnet32', 'resnet44', 'resnet56']) +\n",
        "                             ' (default: resnet20)')\n",
        "\n",
        "    parser.add_argument('--save-dir', dest='save_dir',\n",
        "                        help='The directory used to save the trained models',\n",
        "                        default='save_temp', type=str)\n",
        "    parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
        "                        help='path to latest checkpoint (default: none)')\n",
        "\n",
        "\n",
        "    parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
        "                        help='number of data loading workers (default: 4)')\n",
        "    parser.add_argument('--epochs', default=100, type=int, metavar='N',\n",
        "                        help='number of total epochs to run')\n",
        "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
        "                        help='manual epoch number (useful on restarts)')\n",
        "    parser.add_argument('--batch_size', default=100, type=int,\n",
        "                        metavar='N', help='mini-batch size (default: 100)')\n",
        "    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
        "                        metavar='LR', help='initial learning rate')\n",
        "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
        "                        help='momentum')\n",
        "    parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
        "                        metavar='W', help='weight decay (default: 1e-4)')\n",
        "    parser.add_argument('--print-freq', '-p', default=50, type=int,\n",
        "                        metavar='N', help='print frequency (default: 50)')\n",
        "\n",
        "    parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
        "                        help='evaluate model on validation set')\n",
        "    parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
        "                        help='use pre-trained model')\n",
        "    parser.add_argument('--half', dest='half', action='store_true',\n",
        "                        help='use half-precision(16-bit) ')\n",
        "\n",
        "    parser.add_argument('--save-every', dest='save_every',\n",
        "                        help='Saves checkpoints at every specified number of epochs',\n",
        "                        type=int, default=10)\n",
        "    parser.add_argument('--genie', dest='genie', action='store_true',\n",
        "                        help='whether to use genie erm')\n",
        "    parser.add_argument('--tilting', dest='tilting', action='store_true',\n",
        "                        help='whether to use tilting')\n",
        "\n",
        "\n",
        "    args, unknown_args = parser.parse_known_args()\n",
        "\n",
        "\n",
        "    # Ignore any unknown arguments\n",
        "    if unknown_args:\n",
        "        print(f\"Ignoring unknown arguments: {unknown_args}\")\n",
        "\n",
        "    # Check the save_dir exists or not\n",
        "    if not os.path.exists(args.save_dir):\n",
        "        os.makedirs(args.save_dir)\n",
        "\n",
        "    print(args.arch)\n",
        "\n",
        "    model = torch.nn.DataParallel(resnet.__dict__[args.arch]())\n",
        "    model.cuda()\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "    if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
        "            checkpoint = torch.load(args.resume)\n",
        "            args.start_epoch = checkpoint['epoch']\n",
        "            best_prec1 = checkpoint['best_prec1']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(args.evaluate, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    train_data = CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, 4),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]), download=True)\n",
        "\n",
        "    np.random.seed(1)\n",
        "    num_training = len(train_data.targets)\n",
        "    perm = np.random.permutation(num_training)\n",
        "\n",
        "    if args.genie:\n",
        "        subsets = list(perm[:10000])\n",
        "        train_set = torch.utils.data.Subset(train_data, subsets)\n",
        "        train_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                                    batch_size=args.batch_size, shuffle=True,\n",
        "                                                    num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "    else:\n",
        "        train_data.train_labels = np.array(train_data.targets)\n",
        "        for i in range(20, 100):  # 80 noisy annotators\n",
        "            train_data.train_labels[perm[i * 500:(i + 1) * 500]] = np.random.choice(range(10), 500)\n",
        "        train_data.train_labels = list(train_data.train_labels)\n",
        "        train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                                    batch_size=args.batch_size, shuffle=True,\n",
        "                                                    num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])),\n",
        "        batch_size=128, shuffle=False,\n",
        "        num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "    criterion_vector = nn.CrossEntropyLoss(reduction='none').cuda()\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    if args.half:\n",
        "        model.half()\n",
        "        criterion.half()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
        "                                momentum=args.momentum,\n",
        "                                weight_decay=args.weight_decay)\n",
        "\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                        milestones=[50, 80], last_epoch=args.start_epoch - 1)\n",
        "\n",
        "    if args.arch in ['resnet1202', 'resnet110']:\n",
        "        # for resnet1202 original paper uses lr=0.01 for first 400 minibatches for warm-up\n",
        "        # then switch back. In this setup it will correspond for first epoch.\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = args.lr * 0.1\n",
        "\n",
        "    if args.evaluate:\n",
        "        validate(val_loader, model, criterion)\n",
        "        return\n",
        "\n",
        "    if args.tilting:\n",
        "        print(\"tilting...\")\n",
        "    else:\n",
        "        print(\"not tilting...\")\n",
        "\n",
        "    obj_estimate = 0.1\n",
        "\n",
        "    for epoch in range(args.start_epoch, args.epochs):\n",
        "\n",
        "        # train for one epoch\n",
        "        print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
        "        new_estimate = train(obj_estimate, train_loader, model, criterion_vector, criterion, optimizer, epoch)\n",
        "        obj_estimate = new_estimate\n",
        "        lr_scheduler.step()  # learning rate decay\n",
        "\n",
        "        # evaluate on validation set\n",
        "        prec1 = validate(val_loader, model, criterion)\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        is_best = prec1 > best_prec1\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        "\n",
        "        if epoch > 0 and epoch % args.save_every == 0:\n",
        "            save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'best_prec1': best_prec1,\n",
        "            }, is_best, filename=os.path.join(args.save_dir, 'checkpoint.th'))\n",
        "\n",
        "        save_checkpoint({\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "        }, is_best, filename=os.path.join(args.save_dir, 'model.th'))\n",
        "\n",
        "\n",
        "\n",
        "def train(estimate, train_loader, model, criterion_vector, criterion, optimizer, epoch):\n",
        "    \"\"\"\n",
        "        Run one train epoch\n",
        "    \"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        target = target.cuda()\n",
        "        input_var = input.cuda()\n",
        "        target_var = target\n",
        "        if args.half:\n",
        "            input_var = input_var.half()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # perform optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        output = output.float()\n",
        "        loss = loss.float()\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target)[0]\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                data_time=data_time, loss=losses, top1=top1))\n",
        "    return estimate\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    \"\"\"\n",
        "    Run evaluation\n",
        "    \"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            target = target.cuda()\n",
        "            input_var = input.cuda()\n",
        "            target_var = target.cuda()\n",
        "\n",
        "            if args.half:\n",
        "                input_var = input_var.half()\n",
        "\n",
        "            # compute output\n",
        "            output = model(input_var)\n",
        "            loss = criterion(output, target_var)\n",
        "\n",
        "            output = output.float()\n",
        "            loss = loss.float()\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1 = accuracy(output.data, target)[0]\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                print('Test: [{0}/{1}]\\t'\n",
        "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                    i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                    top1=top1))\n",
        "\n",
        "    print(' * Prec@1 {top1.avg:.3f}'\n",
        "          .format(top1=top1))\n",
        "\n",
        "    return top1.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    \"\"\"\n",
        "    Save the training model\n",
        "    \"\"\"\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "U7eeLKHxR739",
        "outputId": "4552c9fd-ec05-4c0e-ca6b-7be38d0811ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['resnet110', 'resnet1202', 'resnet20', 'resnet32', 'resnet44', 'resnet56']\n",
            "Ignoring unknown arguments: ['-f', '/root/.local/share/jupyter/runtime/kernel-9f7e6480-1e58-4893-b4e9-c1acd77e62f7.json']\n",
            "resnet20\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not tilting...\n",
            "current lr 1.00000e-01\n",
            "Epoch: [0][0/500]\tTime 8.287 (8.287)\tData 0.339 (0.339)\tLoss 4.9151 (4.9151)\tPrec@1 8.000 (8.000)\n",
            "Epoch: [0][50/500]\tTime 0.042 (0.208)\tData 0.004 (0.012)\tLoss 2.1451 (2.7104)\tPrec@1 25.000 (13.373)\n",
            "Epoch: [0][100/500]\tTime 0.043 (0.126)\tData 0.006 (0.010)\tLoss 1.9338 (2.3682)\tPrec@1 32.000 (17.931)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-fa45c6012ded>\u001b[0m in \u001b[0;36m<cell line: 397>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-fa45c6012ded>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'current lr {:.5e}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mnew_estimate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_estimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mobj_estimate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_estimate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# learning rate decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fa45c6012ded>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(estimate, train_loader, model, criterion_vector, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mprec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}